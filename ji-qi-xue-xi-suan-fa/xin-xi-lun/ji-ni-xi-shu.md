# 基尼系数

与之前那两个基于熵的不同，基尼系数采用新的算法来计算数据的不确定度/纯度，基尼系数越小，数据的纯度越高，不确定度越低。我们来看一下基尼系数到底长什么样。

在一个分类问题中，假设有$$v$$个类别，第$$v$$个类别的概率为，则基尼系数为：

$$
\operatorname{Gini}(p)=\sum_{v=1}^{V} p_{v}\left(1-p_{v}\right)=1-\sum_{v=1}^{V} p_{v}^{2}
$$

对于给定样本$$D$$，假设其中有$$k$$个类别，切第$$k$$个类别的数量为，则样本$$D$$的基尼系数为：

$$
\operatorname{Gini}(D)=1-\sum_{v=1}^{V}\left(\frac{\left|A_{v}\right|}{|D|}\right)^{2}
$$

具体来说，我们假设某个离散属性的取值为：

$$
\left\{a^{1}, a^{2}, a^{3}, \ldots a^{V}\right\}
$$

$$A^{v}$$代表所有样本在属性$$a$$上取值为$$a^{v}$$的样本集合。

那么以属性A对数据集$$D$$进行划分，所得到的基尼系数为：

$$
\operatorname{Gini}(D, A)=\sum_{v=1}^{V} \frac{\left|A^{v}\right|}{|D|} \mathrm{Gini}\left(A^{v}\right)
$$

**基尼系数越小，则属性集D的纯度越高。**

我们还是用西瓜数据集为例，计算一下基尼系数，假设我们以色泽属性进行分割，那么就对应着三个数据子集：

* $$A^{1}$$代表青绿色，对应的数据编号为$$ \{1,4,6,10,13,17\} $$，共有6个样本，其中正例3个，负例3个。
* $$A^{2}$$代表乌黑色，对应的数据编号为$$ \{2,3,7,8,9,15\}$$ ，共有6个样本，其中正例4个，负例2个。
* $$A^{3}$$代表浅白色，对应的数据编号为$$ \{5,11,12,14,16\}$$，共有5个样本，其中正例1个，负例4个。

_正例仍代表好瓜与负例仍代表坏瓜。_

则按照色泽进行划分之后的到的基尼系数分别为：

$$
\begin{aligned}
&\mathrm{Gini}\left(A^{1}\right)=1-\left((\frac{3}{6})^2 + (\frac{3}{6})^2 \right)=0.5 \\
&\mathrm{Gini}\left(A^{2}\right)=1-\left((\frac{4}{6})^2 + (\frac{2}{6})^2 \right)=0.444\\
&\mathrm{Gini}\left(A^{3}\right)=1-\left((\frac{1}{5})^2 + (\frac{4}{5})^2 \right)=0.32
\end{aligned}
$$

则根据属性色泽划分之后的基尼系数为：

$$
\begin{aligned}
\text { Gini }(D, A) &= \sum_{v=1}^{V} \frac{\left|A^{v}\right|}{|D|} \mathrm{Gini}\left(A^{v}\right) \\
&=\frac{6}{17}*0.5 + \frac{6}{17}*0.444 + \frac{5}{17}*0.32 \\
&=0.176 + 0.157 + 0.094 \\
&=0.427
\end{aligned}
$$

